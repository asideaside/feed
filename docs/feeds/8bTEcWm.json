{"id":"8bTEcWm","title":"COVER","displayTitle":"COVER","url":"","feedLink":"","isQuery":true,"isEmpty":false,"isHidden":false,"itemCount":6,"items":[{"title":"Delivering New Experiences to Fans While Empowering Talent – Inside COVER’s Licensing Business","url":"https://coveredge.cover-corp.com/en/list/2390","date":1751511600,"author":"cover_yamaguchi","guid":502,"unread":true,"content":"<p>I began my career at a major entertainment company right after graduating, involved in a range of areas like music and talent management. After that, I changed to an entertainment company called Tokyo Otaku Mode where I first started working with 2D content and gained experience as a buyer and a licensee as well as managing partners, which is actually the opposite of the role I have now.<p>After I left Tokyo Otaku Mode, I was job hunting when a friend introduced me to COVER. At that time, I had already accepted an offer from another company, but my friend strongly encouraged me to meet with Mr. Tanigo, saying what an interesting person he is and how much I should really talk to him. So I decided to go ahead and meet with him.</p>Back then, I honestly had no intention of joining, and I was pretty skeptical about VTuber culture in general and looking back now, I realize I probably came across as quite dismissive during my conversation with him.&nbsp;<p>Mr. Tanigo shared his strong passion for hololive production and explained his long-term vision in detail when we sat down and talked. He spoke about how genuinely believes more than anyone else in the potential of hololive production and its talents, and he described exactly what he felt was needed to help that potential grow.&nbsp;</p>Hearing his views made me start to feel that maybe I could contribute to this vision as well, and that I wanted to take on the challenge together, which is what ultimately inspired me to join the company.&nbsp;<p>At the time, Mr. Tanigo was actually looking for someone with experience in product planning and development, but during our conversation, he asked me, “How would you feel about looking after licensing? You’re great at talking with people, and I have a feeling this could really suit you,” which led to me being given the opportunity to lead the launch of the licensing business.</p></p>","contentLength":1873,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Cover x Epic Games: Exploring New VTuber Horizons with Unreal Engine","url":"https://coveredge.cover-corp.com/en/list/2320","date":1750993200,"author":"cover_hirata","guid":473,"unread":true,"content":"<div><div><div><div><p>Managing Director: Takayuki Kawasaki</p></div></div></div></div><div><div><p>Customer Success Director: Noriaki Shinoyama</p></div></div><div><div><ul><li>Ikko Fukuda, Director and CTO&nbsp;</li><li>Tsuyoshi Okugawa (Manager/Graphics Engineer), Art Engineering Team, Technology Development Division, Creative Production Department&nbsp;</li><li>Akitsugu Hirano (Lead Engineer), Development Team #3, Technology Development Division, Creative Production Department</li><li>Hyogo Ito (3D Designer), Unreal Engine Development Team, Technology Development Division, Creative Production Department&nbsp;&nbsp;</li><li>Noriyuki Hiromoto (Graphics Engineer), SPARK inc.</li></ul></div></div><h2>Pursuing Realism and Living Up to Talent Expectations:How VTuber Live Technology is Evolving with Unreal Engine</h2><div><div><p>&nbsp;I recently watched the one-and-a-half year anniversary live performance from ReGLOSS using Unreal Engine and the quality was incredibly high, genuinely moving me. Could you walk us through what led to the decision to incorporate Unreal Engine into this livestream, and how the technology behind your livestream has evolved over time?</p></div></div><div><div><p>Thank you very much. Music livestreams for hololive production originally began with the use of motion capture VR equipment. At the time, there were many limitations in terms of hardware and available space, and from a technical standpoint, it was quite difficult to handle longer streams. When it comes to graphics, improvements haven’t been just one giant leap forward, but rather from steady, incremental progress over time. What’s particularly worth noting is that this evolution hasn’t been driven by technology alone – it’s also thanks to the ever-improving skills of our on-site team members who handle lighting and camera work, as well as the increasing expertise of our production staff.<p>As we continued to evolve our production, we still felt there were limitations in our ability to recreate a true sense of presence and immersion to capture the sheer amount of information and realism that a live concert delivers and translate that in a virtual space. While grappling with those challenges, I happened to see the </p> demo for Unreal Engine 5 released by Unreal Engine, and I was blown away by the sheer volume of detail, making me excited if we were able to use it for our livestreaming. These days, even individual creators are able to produce high quality content using Unreal Engine, so given this shift, we felt it was essential for us as a company to move quickly and begin offering livestreams powered by Unreal Engine as well. That’s why we made the decision to speed up our timeline and adopt the technology so soon.&nbsp;</p></div></div><div><div><p>How has the response to the livestream powered by Unreal Engine been from fans and talents?</p></div></div><div><div><p>One of the major reasons we adopted Unreal Engine was to better support our talents – to help bring to life performances and expressions they envision. As we gave them progress reports throughout the production process, we could sense their growing excitement – a feeling of “we may finally be able to do the things we weren’t able to before.” In fact, we’ve already received numerous requests from other talents saying they’d love to do a livestream using Unreal Engine as well. Being able to provide an environment where we can meet those expectations is incredibly meaningful.&nbsp;&nbsp;<p>The high quality in graphics really surprised and excited fans and talents, even prompting lively discussions on social media, with people speculating about what might be possible with the Unreal Engine. What really stood out among fan reactions was how attentive they were to technical details and how often they would comment on them. We even got comments from those with seemingly quite specialized knowledge noting the incredible use of skeletal mesh for the water effects for instance. It was really encouraging for us to see that level of engagement.&nbsp;</p><p>Internally, we also treated this as a kind of technical showcase and gave non-engineering staff the opportunity to experience the live environment built with Unreal Engine. It was great to see so many people take interest and participate – even those without a technical background.</p><p>I know we have started using Unreal Engine for music livestreams, but it was originally developed as a game engine. In Japan, what kinds of fields is Unreal Engine currently being used in?</p></p></div></div><div><div><p>In Japan, it has been strongly adopted by television broadcasters in particular. Unreal Engine is highly valued in such environments for its efficiency and speed, qualities that are especially important in the fast-paced world of regular programming and drama production.&nbsp; For example, it’s been used in a variety of settings, including shoots for NHK’s historical dramas that use LEDs and commercial network productions, as well as in virtual studios for visual effects work. Recently, stylized expressions () – including toon shading () – have become increasingly common in the anime production field as well. Unreal Engine is now being used in a wide range of visual and broadcast productions, and the number of projects adopting it continues to grow significantly.</p></div></div><p><sup>Note 1: “Stylized” refers to expressing objects or characters in a unique design or applying a consistent visual styleNote 2: “Toon shading” is a technique used to make 3DCG look like hand-drawn illustrations or cel-style animation.</sup></p><div><div><p>In television and other video production on-site, deadlines tend to be very tight, and in the past, there were only a limited number of iterations () possible. But with real-time rendering, teams can now immediately check the results of their work, making it possible to produce higher-quality content more efficiently. The video industry has long made use of dedicated software and middleware, but the biggest advantage of Unreal Engine is that it provides an environment where high-quality visuals can be created in real time. In addition to Unreal Engine itself, we also provide an ecosystem that includes assets like Megascans (), allowing even small teams to produce high-quality content.</p></div></div><p><sup>Note 3: Iteration refers to a development cycle often used in software development and project management, where design development and testing are repeated in short intervalsNote 4: Megascans is a high-quality 3D asset scans library offered by Quixel. It features physically-based rendering with faithfully captured high-resolution details. These assets can be directly exported into Unreal Engine.</sup></p><div><div><p>In fields like video and anime production, Unreal Engine can dramatically streamline the traditional workflow. In fact, directors or supervisors can even build scenes directly in the editor without needing a storyboard. The ability for users to work in a pipeline that closely resembles real-world production has significantly improved trial-and-error speeds – something that many professionals have found especially valuable.</p></div></div><h2>Blending Photorealism and Anime: Engineers’ Innovative Approach to Unreal Engine</h2><div><div><p>This was your first time implementing Unreal Engine, but could you tell us about the technical challenges you faced and any creative solutions you came up with when using it for your livestream?</p></div></div><div><div><p>For this project, I oversaw development direction, and the biggest benefit we saw from adopting Unreal Engine were in the lighting quality and the overall production speed. The lighting design was completed in just a few weeks, which is an incredibly fast turnaround, and the final visual output far exceeded our expectations in terms of expression. Although, bringing together the photorealistic visuals that Unreal Engine excels at with the anime likeness of the hololive talents into the same space did require a great deal of technical ingenuity.&nbsp;</p></div></div><div><div><p>&nbsp;I was in charge of graphics, and the most challenging part for me was finding the right balance between a sense of realism and an anime-style aesthetic that would look visually appealing in a video. We put a lot of effort into blending the talents naturally into the environment, especially in how they interacted with the background, by implementing a “holo-color grading system” and creating a custom post-effect volume, separate from Unreal Engine’s standard post-effects. This setup allowed us to apply grading () separately to the talents and the background, and then apply master grading on top of both. It also allowed us to separately adjust the color grading of the talents and the background based on parameters like the time of day and weather changes as well as made it possible to naturally blend the stylized talents into a photorealistic background.&nbsp;</p></div></div><p><em><sup>Note 5: “Grading” refers to the process of adjusting colors, tones and contrast in a video to create a particular atmosphere or visual world.</sup></em></p><div><div><p>We also had to get creative with Lumen, Unreal Engine’s global illumination system. Using the default Lumen settings made the talents appear overly three-dimensional – almost like figurines – so we adjusted the lighting to tone down that sense of depth while still retaining the ambient lighting of the environment.</p></div></div><div><div><p>&nbsp;I contributed to the project mainly by modifying the engine including developing existing character shaders and implementing post-effects. One of the key challenges was figuring out how to faithfully translate our existing character expressions into Unreal Engine. That simply wouldn’t have been possible without making modifications to the engine. Because Unreal Engine’s G-buffer couldn’t fully accommodate the range of expressions we needed, we implemented a few workarounds including quantizing and compressing the data, and extending the system to allow constant buffers to be added per material.<p>In environments with such a large number of lights active at once, the standard lighting caused the cel-shaded appearance talents to break up a bit. To address this, we implemented a custom lighting system specially for those talents and thanks to this, we were able to maintain consistent anime-style shading even in scenes with more than 50 real-time light sources.</p><p>We also addressed translucency by rendering the relevant materials in a separate buffer using multipass rendering, which allowed us to have deferred lighting for translucent materials.&nbsp;</p></p></div></div><p><sup>: <em>G-buffers store geometric information about objects in a scene, such as normal vectors, albedo (surface color) and depth information. By using a G-buffer, rendering performance can be improved, and more complex lighting calculations can be performed efficiently.&nbsp;</em></sup></p><p>▼Expressions that use over 50 light sources in real time</p><div><div><p>I am in charge of talent-related development, focusing on ways to introduce outlines into talent expressions.</p></div></div><div><div><p>There are two ways of doing this, either with push or post outlines, and we have to make detailed adjustments so that we can switch between the two as necessary depending on how close the camera is. During the live performance, as a production changes from evening to night as time elapses, we adjusted the color grading in real time using Sequencer () for each time period, so that the talents’ movements appear natural. For normal vectors, we originally used SDF textures to control the shading, but this didn’t suit environments with multiple lights and some appearances ended up being less than ideal, so instead of using SDF textures (), we switched to controlling it with vertex normal, which produced far more beautiful shadows.&nbsp;</p></div></div><p><em><sup>Note 7: Sequencer is an editor for creating cut scenes. A series of scenes can be created by putting cameras and characters onto a timeline.</sup></em></p><p><sup><em>Note 8: A type of texture for 3D shapes that uses SDFs (Signed Distance Fields), which can make shape outlines look very smooth by saving the space between an object’s position and a shape, and stronger textures for objects that enlarge/shrink and animations</em>.</sup></p><div><div><p>SDF textures are effective when there is one source of light, but when multiple light sources hit an object, we get bands that we don’t want. For example, when there is an overlap of SDF textures from light that hits from both the left and right, unnatural 2D bands appear creating an unintentional anime likeness. Therefore, we reverted back to a method of editing vertex normals like those used in fighting video games where anime-like characters appear, which we thought made sense for environments with multiple light sources.&nbsp;</p></div></div><div><div><p>Also, similar to live music concerts, there were camera exposure issues, where talents are too bright when a spotlight, like a real camera at a concert, hits them, or too dark when the exposure is adjusted.&nbsp;</p></div></div><div><div><p>In order to address such issues, we introduced a system that corrects exposure for each camera using a MIDI controller. We needed to calculate outline extrusion to align with camera angles, because live cameras use 200mm or 300mm telephoto lens settings.&nbsp;</p></div></div><div><div><p>We use the Live Link plugin () with our cameras, but this time, we also used the FreeD protocol ( to link our Panasonic camera remotes so we could control the virtual cameras to make it feel like an actual live broadcast, and thanks to our staff, some of whom have knowledge in the TV field, we were able to create a workflow not too dissimilar to that of one. Certain staff members commented that although we are using Unreal Engine, what we are doing is no different from filming in reality, so it turned out to be a good example of combining technology from staff who originally worked in TV and Unreal Engine.&nbsp;</p></div></div><p><em><sup>Note 9: An Unreal Engine plugin for streaming data to Unreal Engine from external software and devices in real time. It can provide a basis for sharing information in real time such as animation data and camera movements.&nbsp;</sup></em></p><p><em><sup>Note 10: A communication standard for directly transmitting camera tracking information (pan, tilt, zoom, etc.) to a control system in order to coordinate camera movements with computer graphics content.</sup></em></p><div><div><p>We feel that there is an extremely high capacity to accommodate livestream concepts and talents’ wishes since using Unreal Engine to continue to develop our content. Original concepts, such as weather changes and the elapsing of time, can be implemented with an exceptionally high level of quality, and it has contributed to improved realism and elevated our livestreams, through such lighting improvements and by being able to have interactive expressions such as water bouncing off of the bodies of talents, or rain streaming down faces.&nbsp;</p></div></div><div><div><p>That’s great. It seems like there are various ways to create anime likenesses from a system optimized for photorealism. What measures did you have in place to optimize frame rate and lag, also vitally important for livestreams?</p></div></div><div><div><p>Our biggest issue was using over 50 light sources once activating ray tracing . First of all, we thoroughly managed channels such as light that did or did not cast a shadow or those that cast light. Also, we used and optimized Variable Rate Shading (VRS) , as a high amount of translucent light puts a lot of stress on the system. Originally, we also wanted to use VRS as it’s adaptive, but we set a constant unit due to time restrictions. In spite of this, we still got 2 to 3 times more speed.We greatly customized DMX (Note 13) light shaft calculations and implemented measures such as reducing the number of steps for ray marching (Note 14), and also optimized packaging. By minimizing the dependency, packaging that has usually taken about an hour was done in roughly 5-10 mins – iteration speed improvements were hugely important from a development efficiency standpoint.&nbsp;</p></div></div><p><em><sup>Note 11: A kind of technology that generates real images by simulating the volume, angle, refraction, and reflection of the rays of light via a computer. This is used to accurately represent the reflection, refraction and shadowing of light.</sup></em></p><p><em><sup>Note 12: Variable Rate Shading (VRS) is a type of rendering technology for improving performance and picture quality in game development that allows for pixel shading rates (frequency of processing one pixel) to be actively adjusted to reduce the load when processing images. </sup></em></p><p><em><sup>Note 13: DMX (Digital Multiplex) is a digital transmission network that is used to control stage lighting and effects for concerts and events, from the more simple to complicated ones.&nbsp;</sup></em></p><p><em><sup>Note 14: A kind of rendering technique in the ray tracing field.</sup></em></p><div><div><p>We were doing a lot of customization within Unreal Engine, such as compressing values to 4 bit to preserve the G-buffer, and packing multiple parameters into single channels. Also, to handle translucent areas, we increased deferred rendering (deferred shading) , and increased speed making use of stencil masking. We are also steadily optimizing how we deal with divergent branches in the Shader.</p></div></div><div><div><p>CPU optimization was also important. In particular, we greatly improved the performance of the editor while in use by introducing C++ to DMX plugin blueprint processes. In the future, we would like to continue this optimization to make both real-time editing using the editor and use in livestreams possible together. In terms of motion capture, we are using COVER’s original system, and we also developed an original system for integrating data from Vicon () to Motion Builder , and then to Unreal Engine.&nbsp;</p></div></div><div><div><p>We could also use Live Link for motion capture as well, but we needed a multi-engine approach because we were developing with both Unreal Engine and Unity (). As well as this, we are developing our own system that takes into account redundancy support and transmission load distribution, so that issues never occur during livestreams.</p></div></div><p><em><sup>Note 15: A type of 3D computer graphics rendering technique where complex light can be effectively expressed in real time. Note 16: The name of a motion capture system<p>Note 17: The name of a real-time 3D character animation software</p>Note 18: The game engine developed by Unity Technologies</sup></em></p><div><div><p>Very interesting. Thank you very much. I’m extremely interested in this example of actual camera operators and lighting staff directly controlling Unreal Engine rather than engineers.</p></div></div><div><div><p>Traditionally, we have needed to allow time to transfer what we designed using the lighting simulation software to the game engine, but this time, we had lighting experts set fixtures () and patch () these designs directly into Unreal Engine. This new trend of having professional lighting staff use the game engine felt really revolutionary.&nbsp;</p></div></div><p><em><sup>(Note 19) Lighting equipment that use and are controlled by DMX protocols</sup></em><em><sup>(Note 20) Making partial revision and changes</sup></em></p><h2>The Importance of a Multitude of Skills and a Support Network: Strengths and Prospects of Development Using Unreal Engine</h2><div><div><p>What advantages and/or costs have you felt there have been by introducing Unreal Engine and how has this affected the organization?</p></div></div><div><div><p>The speed from production to implementation has been so helpful! Unreal Engine is full of high quality features meaning that even non-engineers can help in the development process, so it took just weeks after we had the concept of the concert to finish the stage prototype.</p></div></div><div><div><p>We were able to take a balanced approach over a 7-8 month period for this concert production, by recompiling the engine where necessary while taking full advantage of Unreal Engine’s existing functions, such as the DMX plugin. Unreal Engine is super flexible, being able to handle a variety of different situations, so high quality content can be made in quick time for short-term projects without recompiling the engine, and for large-scale projects, one of the advantages is that our own expressions can be tracked by modifying the source code.<p>There was a mix of staff on this production from a wide range of industries, including gaming, TV, and mobile, and everyone’s skills seemed to fit the project well. However, what kinds of skillsets do Epic Games expect people to have and are required when using Unreal Engine?</p></p></div></div><div><div><p>&nbsp;I deal with a lot of different customers in technical support, but regardless of the industry you are in, it is extremely important to be fully across the concept of real-time rendering. We are coming up with a number of ways to draw frames in such short 16-millisecond amounts of time for the gaming industry, so understanding what can be done under real-time restrictions is so crucial when using Unreal Engine. Sometimes people used to more conventional forms of offline rendering suddenly start using Unreal Engine and are surprised by how restricted they feel. Having gaming industry graphics professionals such as yourself (Okugawa) is such a huge asset to COVER.&nbsp;&nbsp;<p>Oh, and one more thing: when working on livestreams, it is necessary to have multiple instances of Unreal Engine and have them in sync. Within Unreal Engine, there is a range of tools from those on the network level to synchronizing monitors, but you also need the knowledge to understand what is causing any problems that arise.&nbsp;&nbsp;&nbsp;</p></p></div></div><div><div><p>It definitely seems that you need a strong mix of people in an engineering team with a diverse set of skills from fields ranging from gaming to film for the production side of livestreams. Could you please tell us about what kind of support you, at Epic Games, provide Unreal Engine users?</p></div></div><div><div><p>We have our official Epic Pro Support subscription add-on, as well as our <a href=\"https://dev.epicgames.com/community/\">Epic Developer Community</a> forums where users help each other and exchange information. With Epic Pro Support, we provide support for those with highly technical issues and supply the latest information, as well as sharing know-how about profiling and optimization from what we actually do on-site. Our team mainly provides community support: we have recently started sharing Q&amp;As we have received through our pro support subscription with our Epic Developer Community, after removing any confidential information, giving a whole lot of developers access to quality information.</p></div></div><div><div><p>Behind this initiative to share Q&amp;A with the public are the strong intentions from our founder (of Epic Games), Tim Sweeney. Tim himself began his career in game development with just a single computer, and truly wishes to support all those, from indie games developers to students, aiming to be creators, at Epic Games are striving to create an environment where creators can grow and develop.&nbsp;</p></div></div><div><div><p>Also, there are passionate fans of Unreal Engine everywhere organizing their own independent community events, to which we at Epic Games actively try to attend. There are Unreal Engine enthusiasts not only in Tokyo, Osaka and Fukuoka, but in a lot of different places with a real energy to excite the community around them. We really value these fans and want to support them as best we can.&nbsp;</p></div></div><h2>Evolving Technology for a New Future:COVER and Epic Games Redefining Expressions and Entertainment with Unreal Engine</h2><div><div><p>Could you tell us what plans Epic Games has for the future and the direction the development of Unreal Engine is heading?</p></div></div><div><div><p>We are currently envisioning a dual-axis approach to the development of Unreal Engine at the moment: the vertical evolution of quality along with the horizontal expansion of the platform and its userbase. One of the big themes for Epic Games as a whole is the strengthening of our support for mobile platforms, and optimization so that we can provide high-quality content to a wider range of devices.&nbsp;&nbsp;<p>Also, our metaverse vision is also strategically important for us. Our global expansion through Fortnite is a great representation of this, with Unreal Engine at the heart of its technical infrastructure. We are focusing a lot on UGC (user-generated content) through our </p><a href=\"https://www.unrealengine.com/en-US/uses/uefn-unreal-editor-for-fortnite\">UEFN (Unreal Editor for Fortnite)</a>, and creating an environment where not only engineers but regular users can also produce their own content.</p></div></div><div><div><p>From a technological perspective, as well as improvements in graphics, we believe that movement and motion expressions are becoming an important topic. We (at Epic Games) have a comprehensive service where people can create a realistic human called MetaHuman, and we have recently added a function called MetaHuman Animator where, just by filming your own expressions using an iPhone, you can transfer these movements to MetaHuman. At the moment, we are focusing on developing the realism of digital humans, but we also plan to expand this so that this technology can be applied to various talents and other expressions. By further improving the real-time nature of it, we expect that even more natural and interactive expressions will be possible.<p>The use of the fully immersive display </p><a href=\"https://www.thesphere.com/\">Sphere</a> in Las Vegas has also received quite a lot of attention recently. In most cases, a video that has been previously rendered is projected onto a screen, but more and more cases of projections in real-time using Unreal Engine are emerging. For example, the spherical screen of Sphere was used at a live concert for the band Phish in the US, who are known for their improvisation, to project graphics in real-time using Unreal Engine to match their performance. A Fortnite event in New York also had multiple screens around Times Square that were being controlled simultaneously and linked to artists’ performances.&nbsp;</p></div></div><div><div><p>We hope to use Unreal Engine for more of these kinds of immersive experiences within Japan as well. <a href=\"https://www.unrealengine.com/en-US/news/unreal-fest-2025-is-coming-to-a-city-near-you\">Unreal Fest 2025 Tokyo</a> is planned for November 14 and 15 of this year in Takanawa, Tokyo, where all the latest use cases of Unreal Engine in various industries and information on the technology will be shared over the 2 days on an even bigger scale than last year, so we hope you can join us if you are interested.</p></div></div><div><div><p>What challenges would COVER like to undertake using Unreal Engine in the future?</p></div></div><div><div><p>We would like to further improve the quality of our livestreams, and for not only that, but for a range of other events as well. For instance, every summer, hololive holds a swimsuit event and with Unreal Engine, it may even be possible to have talents swimming underwater as an example. We also hope to increase our AR (augmented reality) content combining both real-life and animation together, and with how compatible it is with real-time lighting, we also have our sights on developing our on-location content and TV programs too.&nbsp;&nbsp;&nbsp;&nbsp;We are also considering content that features more interactivity with fans, taking advantage of its unique features as a game engine. At COVER, we are also developing a metaverse, so we hope to use Unreal Engine to develop content in the 3D space, and not just video streams.&nbsp;<p>We can see from this chat that a range of experts are now taking on the challenge of blending the seemingly contradictory elements of realism and animated expression. The similarities of both Epic Games and COVER, who are supporting creators through technological development as well as talents and their aspirations, opens up a whole new world of possibilities for VTuber entertainment.</p></p></div></div>","contentLength":26574,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"We Held Our Third All- Employee Meeting and Announced the COVER AWARD 2024 Winners","url":"https://coveredge.cover-corp.com/en/list/2275","date":1750989600,"author":"平松梨沙","guid":472,"unread":true,"content":"<p>On May 27, 2025, we held our third COVER Corporation All-Employee Meeting with over 700 employees in attendance, and included opening remarks from the directors, the announcement of the COVER AWARD 2024, a group photo session, and a casual networking reception. President and CEO Motoaki Tanigo reflected on the company’s journey so far, with the message, “Let’s not be afraid of change and evolve.”&nbsp;</p><p>The COVER AWARD 2024 honored individuals and projects from the previous year that exemplified the company’s values and delivered meaningful results.</p><p>Individual awards were presented to a member from the Sales Development Division (for securing national clients and proposing innovative promotions), a member from the Creative Production Division (for promoting Houshou Marine’s Beauty Witch model project and managing quality control for a new 3D model), and a member from the Product Development Division (for delivering live event merchandise on a tight schedule while maintaining a high-quality product). During the awards ceremony, each division head shared their thoughts on why the recipients were selected, followed by presentations from the winners themselves, reflecting on the projects they had worked on over the past year.&nbsp;</p><p>Two projects were selected for the Project Awards.&nbsp;The offline event “hololive GAMERS fes. Cho-Cho-Cho-Cho GAMERS” received their award for delivering an offline experience focused on gameplay.&nbsp;<p>The “Virtual Concert Development with Unreal Engine” project was awarded for bringing ReGLOSS 3D LIVE “Sakura Mirage” to life by evolving our technology through the effective use of existing assets and expertise gained in a Unity-based environment.</p></p><p>The event brought employees from different divisions together, deepening everyone’s mutual understanding and connections with each other, and providing inspiration for the year ahead.</p><p><strong>Note: All division affiliations are as of FY 2024.</strong></p>","contentLength":1939,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Report from the hololive production Official Shop: A New Transmission Hub for VTuber Culture – From Tokyo to the World","url":"https://coveredge.cover-corp.com/en/list/2228","date":1750302000,"author":"cover_hirata","guid":442,"unread":true,"content":"<h2>An Atmosphere Built Upon a Station. A New Fan Experience Full of Original Illustrations and Unique Content.</h2><p>The store, which will be available until spring 2026, is expected to be a new transmission hub for VTuber culture right on Tokyo’s doorstep, a destination for domestic and international tourists.One of the unique features of this shop is the original merchandise that changes depending on the time of year. For example, in December 2024, a range of products featuring hololive production talents in hololive Station Costumes designed by illustrator Hiragi to look like station attendants were released, including acrylic stands and name tag-style acrylic badges, which received a lot of support from fans. Inside the shop, one can hear exclusive in-store announcements recorded by the talents, and find handwritten signatures and comments from talents scattered all over the shop, creating a station-like atmosphere and bringing together all sorts of people. <sup>*Announcements will change at different times of the year.</sup><p>Unique initiatives can also be taken on, as the store can be easily adapted to suit requests from talents. Special campaigns or projects are implemented to coincide with a talent’s live concert or an album release, which talents in turn have brought up during their livestreams. Fans can look forward to different projects and campaigns throughout the year, with new themed merchandise releases and announcements whenever they visit the store.</p></p><h2>Best-Sellers and Creating Unique, Valued Experiences Through Offline Stores</h2><p>When asked what products are the most prolific sellers, KIDDY LAND’s Kaneaki Kubushiro, the shop manager, said that the station attendant uniform series of original merchandise and confectionery has been particularly popular.</p><p>“We consistently sell 5-10 units of confectionery featuring the talents in their hololive Station Costumes every hour, with certain customers buying the maximum amount they can for restricted merchandise” he said, talking about the high demand for souvenirs taking full advantage of the prime location that is Tokyo Station.</p><p>hololive Station Costume acrylic stands are also strong sellers, with many fans coming to the store in search of their oshi’s design, a highly valued piece of memorabilia.</p><p>He spoke about their popularity as these merchandise are easily portable for fans’ : “The plushies and mascots have also been well-received because their design is perfect for daily use: they are a good size for fans to store in or decorate their bags with, so they can have one or more with them all the time. We get many customers who buy plushies of their oshi in bulk, so sales rival those of the hololive Station series.”</p><p>The shop offers different experience value for fans, who have mainly shopped online, in physically coming to the store and actually holding the products in their hands before choosing their purchases.</p><p>“I was thrilled to be able to see and choose my oshi’s plushies in person to see how big they were in actuality and how they felt,” said a male Sakura Miko fan hailing from Chiba Prefecture, who visited the store for the first time: a visit that coincided with a cheer screening in Shinagawa, Tokyo.</p><p>Another male customer, who had been to the shop about 3 or 4 times to support Kazama Iroha,&nbsp; places importance on the value of collector’s items, elaborating on his specific reason for being at the shop: “Because my oshi, Kazama Iroha, ends her sentences with “ござる” (), there is the wordplay “ござるの5” (), and so I want to collect 5 (“” in Japanese) of her plushies. I already have one at home, so I bought four more.”&nbsp;</p><p>Kubushiro also talked about how popular the handwritten signature displays were, as fans can only see them because there is a physical store: “These are also extremely popular. Photos [of these displays] actively get circulated around social media because almost everyone who comes to the shop wants to take a picture of them, and we even get a lot of people asking us where their oshi’s signature is. These signature displays are valuable because the talents actually came to sign them in person, so you can only see them here, which has pleased a lot of customers over the first month since opening.”</p><p>The shop is a new point of contact between fans and talents, offering special experiences that one cannot get online. It contributes to further stimulating the fan community, where there is tremendous value in “real” elements at a physical shop like this in a landscape where the digital medium is the main battleground for VTubers.</p><p>“What has particularly left an impression on me is seeing customers lining up patiently while holding a suitcase or a huge backpack. Despite having such heavy luggage with them, many customers come ‘only wanting to buy one item.’ The crowds get really lively when there’s an ongoing campaign or event,” said Kubushiro, also mentioning that there are often lines of up to 50 people outside the shop before and after live events.&nbsp;</p><h2>The Global Expansion of VTuber Culture and hololive production from the Perspective of a Diverse Fanbase</h2><p>When asked who makes up the main clientele at the shop, Kubushiro responded, “About 70-80% are male, with about 20-30% from overseas. In particular, we get more customers from Asia, but on holidays we get westerners coming in as well.” He also mentioned that tax-free purchases can be made as part of the shop’s efforts to appeal to incoming tourists.</p><p>We asked a female customer, who was visiting the store to get a Fuwawa Abyssgard random card and had visited about three times so far, about her impressions of the shop: “There are a lot of overseas visitors here early in the morning on weekdays.”</p><p>When looking at customer trends a little deeper, we can see that VTubers are supported by many age groups, with many families also visiting the shop. We spoke to a family who were at the shop with their 10-year-old son, a Sakura Miko fan, about how they became fans of hololive: “We originally started out watching game livestreams, which is how we first heard about VTubers. It was because there were some VTubers among these video game streamers that we started enjoying VTuber videos as a family.”</p><p>We also asked an elementary schoolgirl, a fan of Hoshimachi Suisei, making the most of her winter vacation and visiting the shop with her family from Kawasaki about how she came to know about hololive: “I became a fan after hearing her sing on YouTube, and now I support her wholeheartedly.”</p><p>A male fan in his 40s, visiting the shop to buy Tokoyami Towa merchandise for his colleague, talked about music content as the gateway for new fans: “I am stopping in on the way to a jazz concert. I am a big music lover, and first learned about VTubers through Hoshimachi Suisei’s appearance on THE FIRST TAKE, and from then on I was a fan. I am planning on getting Hoshimachi Suisei’s upcoming LP.”</p><h2>A Hub for Fans Across the Globe. An Offline Store Opening Doors to New Possibilities.</h2><p>Store manager Kubushiro, based on what he has witnessed in Tokyo, spoke about the shop’s prospects: “We will continue to manage this shop by prioritizing the special feelings people get when buying a particular product, or looking forward to seeing something at the shop. I hope to be able to continue developing this store, making full use of the space here at Tokyo Station for 1, 2, even 3 years to come, and based on the success we’ve had here at Tokyo Station, expand to have more locations all over Japan.”For instance, he envisions a future with an Osaka store that fans can visit whenever a concert is held there.&nbsp;</p><p>COVER President Tanigo still has the vision he has had since the company’s inception of “wanting to create a company that breaks through onto the global stage with Japanese entertainment,” and continues to pour all of his effort into making people more aware of VTubers both within Japan and on a global scale. Establishing a hololive production Official Shop in such an international location like Tokyo Station, where an abundance of overseas tourists can also easily visit the store, is an excellent opportunity for, not only domestic fans, but fans and tourists from all over the world to experience VTuber culture, and a step towards being able to share VTuber culture with so many more people.&nbsp;&nbsp;</p><p>There will be a lot of interest in what sort of possibilities this new hub on Tokyo’s doorstep can bring to the future development of VTuber culture, as a space for experiencing the world of hololive production and a place where fans from all over the world can gather.</p><p><sup>*This article is based on interviews conducted on December 28, 2024, and may differ from current information.</sup></p><h3>First Store in West Japan! hololive production official shop in Osaka Umeda Opening Soon!</h3><p>Shop Name: hololive production official shop in Osaka Umeda<p>Location: B1F North Building, Hankyu Sanban Gai, 1-1-3 Shibata, Kita-ku, Osaka</p>Dates: June 27, 2025 – Spring 2026<p>Opening Hours:&nbsp; 10:00 AM – 9:00 PM (JST)</p><sup>*Opening hours will follow HANKYU SANBAN GAI hours of business.</sup><a href=\"https://hololive.hololivepro.com/en/events/shopumeda/\" target=\"_blank\" rel=\"noreferrer noopener\"><strong>https://hololive.hololivepro.com/en/events/shopumeda/</strong></a></p>","contentLength":9189,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Transcending Age and Language: hololive SUPER EXPO 2025 Attendee Interviews","url":"https://coveredge.cover-corp.com/en/list/1909","date":1749092400,"author":"cover_yamaguchi","guid":374,"unread":true,"content":"<h2>Kids Influencing Parents: Enjoying hololive as a Family</h2><p>A mother of a son in the 2nd grade of junior high school visiting from Hokkaido prints stickers at the Magical Girl holoWitches! booth as she enjoys EXPO with her son and husband as a family. “I’m here with my son because he’s a fan. We try to watch streams together as a family when we have the time,” she told us. Her son also went on to say, “My oshis are Usada Pekora and Murasaki Shion. I became a fan of hololive because of a smartphone game collab they did.”</p><p>They explained that they have experienced going to a movie theater in Hokkaido in the past for a live viewing, but this time they planned to go to the live concert the following day, which was going to be their first time watching a hololive performance live, so they were really looking forward to it. The son has a lot of merchandise in his room, and told us that hololive for him is one of the “joys in life.”</p><p>We also spoke to an uncle-niece duo from Saitama who were enjoying some of the EXPO-exclusive food who told us that they “became fans of hololive from watching YouTube Shorts.” The man continued, “I realised that my niece was also a fan when she bought hololive wafers,” and that EXPO 2025 was the first event they had attended.&nbsp;</p><p>He went on to say that, “hololive is so comforting for me,” and his niece also expressed her love for hololive music and the trading card game (TCG): “My favorite song is Captain Houshou Marine’s “Bishoujyo Muzai♡Pirates. I have also played in a hOCG tournament before.” She continued telling us her dreams: “I want to be a VTuber in the future. I’m designing characters with my school friend,” and when asked about why hololive is so appealing, she responded from the genuine perspective of a schoolchild, “Everyone is so fun and are like friends to me.”</p><h2>We Learned How to Sew! Hobbies and Community Through hololive</h2><p>When asked about their thoughts on EXPO, three friends in their 20s from Chiba and Tokyo who had come in hololive Indonesia 1st Generation cosplay said, “We had been looking forward to our oshis’ food! Moona-chan’s (Moona Hoshinova) Nasi Goreng came with a postcard and it tasted really good!”</p><p>The girls, who arrived at the event at 6:30 AM on the first train of the day, had started making their costumes a month prior. “We bought all the material separately to suit our costumes.” they told us. “When COVID-19 hit, we couldn’t go outside so we started watching streams, which was something we were still able to enjoy without leaving the house,” they replied when asked about how they got into hololive. They were also addicted to hololive Indonesia content as a part of that.&nbsp;</p><p>They also talked about overcoming language barriers and communicating across borders: “We couldn’t understand Indonesian at all in the beginning, but gradually started picking it up. Even now, we are looking up things in Indonesian, and interacting with Indonesian fans as well.”“hololive is one of our joys in life; we live for it. We usually wake up watching hololive and fall asleep to it too. It’s always there by our side regardless of whether we’re sad or happy.”<p>They even gained new hobbies: “We’ve even learned how to sew thanks to cosplaying.”</p></p><p>Two self-professed otaku friends in their 20s came from Osaka and Tokyo to attend both days of EXPO. They told us that they planned to cosplay on the second day as Houshou Marine in costumes that they made by hand together. “We were originally VTuber fans, and then got into hololive through watching 3rd Generation video shorts. We’ll definitely be going to our oshi’s live concerts now!” said the hololive fans of four years.“The Magical Girl holoWitches! booth was really good. We were really moved by the costumes there,” they responded about EXPO 2025.<p>Their passion for hololive was evident as they spoke: “We watch our oshis every day: streams on our commutes and when we’re getting ready. We put on archived content, and it always feels like they’re with us. hololive is our lifeline—we couldn’t survive without it.”</p></p><p>Another fan of 3-4 years in their 40s hailing from Tokyo was with plushies of his oshi Tsunomaki Watame he had brought, enjoying an EXPO-exclusive drink. He told us that he had arrived at 7 in the morning and “was glad to see the mascot parade, something that [he doesn’t] normally get to see.”</p><p>He spoke about the appeal of hololive: “It is what comforts me on a daily basis.”“When I recommend hololive to people, I tell them that there are so many different kinds of VTubers, so they can definitely find one that suits them.”<p>He was at EXPO with two of his friends who gained another common interest thanks to hololive: “They are longtime friends of mine who became fans of hololive because of my recommendations.”</p></p><h2>hololive Transcending Borders: From Online Encounters to Real-Life Friendships</h2><p>A fan of 5 years in his 30s who had traveled to Japan all the way from the Netherlands spoke about his love of cosplaying: “I really wanted to cosplay today, but I couldn’t get a ticket.”“I have been cosplaying for over half of my life,” he asserted, stating that he had started cosplaying when he was 17. “I was really looking forward to the hololive English booth (ENigmatic Recollection). I’m so glad I was able to see the booth where all the members are together for the first time.”</p><p>A HOLOSTARS fan in her 20s who had traveled from Kanagawa talked to us about her oshis Rikka, Hanasaki Miyabi and Minase Rio and how she came across hololive production: “I started getting into them through watching their live content on TikTok about 2-3 years ago.”“I was originally a fan of other streamers, but HOLOSTARS was the reason I became interested in VTubers,” she said, also mentioning that she has a channel membership on YouTube.</p><p>Four Oozora Subaru fans who met on social media (one of whom was in Japan from South Korea) told us that “[they] occasionally meet offline!”The one from South Korea also went on to say, “I first came across hololive at the start of 2022. Even in South Korea, there are events and collab cafes, and there’s even a live viewing for today’s event (EXPO).”</p><p>They also told us from each of their perspectives what hololive means to the four of them: “It’s a place that gives us energy.”“I get energized from Subaru-chan’s (Oozora Subaru) streams.”“It’s entertainment that makes you feel positive.”<p>“I feel really close with them because we see not only how they are on regular streams, but who they are in daily life too.”</p>“There’s so much content in the archive that you can never get sick of it.”</p><h2>EXPO: The Culmination of Diverse Connections Made Through hololive</h2><p>We heard from people from all walks of life through these interviews over the two days at hololive SUPER EXPO 2025 Supported By BANDAI/hololive 6th fes. Color Rise Harmony at Makuhari Messe, showcasing how hololive can be enjoyed by anyone regardless of age, gender or nationality, and connects people through fan interaction. Whether you are a school student, adult, family, friends with a common interest or by yourself, hololive is a place for everyone to enjoy in their own way.</p><p>We also heard how much hololive production means to people, with answers like “It’s part of my daily life,” “I live for hololive,” and “hololive comforts me,” giving us a little insight into how hololive is more than just a mere hobby for some.&nbsp;&nbsp;</p><p>Stay tuned here on COVERedge for more on the constant evolution of hololive production, bringing fans together regardless of talent and fan relationships.&nbsp;</p><p>(Please also check out interviews with staff and booth representatives about the booths that featured at EXPO 2025 in Parts 1 and 2.)</p>","contentLength":7833,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Inside the hololive OFFICIAL CARD GAME: COVER and Bushiroad Share Untold Stories and their Vision for the Future","url":"https://coveredge.cover-corp.com/en/list/1889","date":1748574000,"author":"cover_yamaguchi","guid":359,"unread":true,"content":"<p>I started by buying various card games in Akihabara and studying them. At the time, I was also acting as manager of the commercialization team, so from launch to release, it felt like I was just constantly running full steam ahead. Honestly, those days were such a whirlwind that I barely even remember them…(lol)<p>I started working with Kawatsu in March 2024 and I clearly remember being asked, “How many people are working with you?” and answering, “It’s just me.”&nbsp; Every time I explained the situation, so many people told me, “That’s insane!” (lol). Nevertheless, it was thanks to the support of my colleagues in other departments and collaborators such as Kawatsu that we were able to reach the point where the game was ready for release. I also felt I could draw on my own personal childhood memories of playing card games, which helped me a lot through this process.</p></p>","contentLength":890,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null}],"tags":["COVER"]}